# -*- coding: utf-8 -*-
"""Test Model #WFH 11 Mei .ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/14g6tnXi1vIOKkukjE_qspsaSCKovXbi2
"""

from google.colab import drive
from google.colab.output import eval_js
from IPython.display import display, Javascript
from IPython.display import display, Javascript
from google.colab.output import eval_js
from google.colab.patches import cv2_imshow
from base64 import b64decode, b64encode
import numpy as np
from PIL import Image
import io
import cv2
drive.mount('/content/drive')

from keras.models import Sequential, Model
from keras.layers import Reshape, Activation, Conv2D, Input, MaxPooling2D, BatchNormalization, Flatten, Dense
from keras.layers.advanced_activations import LeakyReLU
from keras import regularizers, initializers
import matplotlib.pyplot as plt
import matplotlib.patches as patches
import numpy as np
import tensorflow as tf
import os
import cv2
import math
import tensorflow as tf
import copy
from keras.models import load_model
from tqdm import tqdm
tf.compat.v1.disable_eager_execution()

folder_citra_train_anno = "/content/drive/My Drive/KULIAH/TA/PROGRAM/dataset/INRIAPerson/Train/annotations"
folder_citra_test_anno = "/content/drive/My Drive/KULIAH/TA/PROGRAM/dataset/INRIAPerson/Test/annotations"
ANCHOR_BOX = np.array([[0.20392486, 0.63848327],
                       [0.09765612, 0.35163892],
                       [0.3341204, 0.69663537],
                       [0.13659861, 0.50890373],
                       [0.06016183, 0.22247988]])
ANCHOR_BOX = ANCHOR_BOX* 416 / 32
BATCH_SIZE=64
object_coord_scale = 1
object_conf_scale = 5
noobject_conf_scale = 0.5

#MODEL

def conv_batch_lrelu(input_tensor, numfilter, dim, strides=1):
    input_tensor = Conv2D(numfilter, (dim, dim), strides=strides, padding='same',
                        # kernel_regularizer=regularizers.l2(0.0005),
                        # kernel_initializer=initializers.TruncatedNormal(stddev=0.1),
                        # use_bias=False
                    )(input_tensor)
    input_tensor = BatchNormalization()(input_tensor)
    return LeakyReLU(alpha=0.1)(input_tensor)

def TinyYOLO2Model():
  model_in = Input((416, 416, 3))
  model = model_in
  for i in range(0, 5):
        model = conv_batch_lrelu(model, 16 * 2**i, 3)
        model = MaxPooling2D(2, padding='valid')(model)

  model = conv_batch_lrelu(model, 512, 3)
  model = MaxPooling2D(2, 1, padding='same')(model)

  model = conv_batch_lrelu(model, 1024, 3)
  model = conv_batch_lrelu(model, 1024, 3)
        
  n_outputs = len(ANCHOR_BOX) * (5)

  model = Conv2D(n_outputs, (1, 1), padding='same', activation='linear')(model)

  model_out = Reshape([13, 13, 5, 4 + 1])(model)
 
  # return Model(inputs=model_in, outputs=model_out)
  return Model(inputs=model_in, outputs=model_out)

mmodel=TinyYOLO2Model()
# mmodel.summary()


# Fine-tuning
# freeze first 8 layers
for layer in mmodel.layers:
    layer.trainable = False
# Add new, randomized final 3 layers with new class size
connecting_layer = mmodel.layers[-4].output
top_model = Conv2D(len(ANCHOR_BOX) * (4 + 1), (1, 1), strides=(1, 1), kernel_initializer='he_normal') (connecting_layer)
top_model = Activation('linear') (top_model)
top_model = Reshape((13, 13, len(ANCHOR_BOX), 4 + 1)) (top_model)
new_model = Model(mmodel.input, top_model)
# new_model.summary()

def parse_anotasi(annotasi_dir):
    all_img = []
    for file_annotasi in sorted(os.listdir(annotasi_dir)):

        temp = open(annotasi_dir + '/' + file_annotasi, "r", encoding="ISO-8859-1")
        label_percitra = {}
        temp_labelobj = []

        for line in temp:
            if 'Image filename' in line:
                a = (line.index('"'))
                temp_lokasi_citra = (line[a + 1:-2])
                label_percitra[
                    'filename'] = '/content/drive/My Drive/KULIAH/TA/PROGRAM/dataset/INRIAPerson/' + temp_lokasi_citra

            if 'Image size' in line:
                w = line[25:29]
                h = line[31:35]
                label_percitra['height'] = h
                label_percitra['width'] = w

            if 'Center point on object' in line:
                if 'person' in line:
                    temp_label = 'person'

                ##CARI ANOTASI BOUNDING BOX
                for line_2 in temp:
                    a = line_2.index(":")
                    temp_line_xyminmax = line_2[a + 2:]
                    for char in temp_line_xyminmax:
                        if char in "()-,\n":
                            temp_line_xyminmax = temp_line_xyminmax.replace(char, '')
                    temp_line_xyminmax = temp_line_xyminmax.split(" ")
                    xmin = int(temp_line_xyminmax[0])
                    ymin = int(temp_line_xyminmax[1])
                    xmax = int(temp_line_xyminmax[3])
                    ymax = int(temp_line_xyminmax[4])
                    break

                temp_dic = {}

                # temp_dic['xmin'] = xmin
                # temp_dic['ymin'] = ymin
                # temp_dic['xmax'] = xmax
                # temp_dic['ymax'] = ymax
                #
                #
                # konversi xy min max ke dari ukuran asli citra ke 416x416
                # w,h ukuran citra asli

                temp_dic['xmin'] = int(int(xmin) * float(416) / float(w))
                temp_dic['ymin'] = int(int(ymin) * float(416) / float(h))
                temp_dic['xmax'] = int(int(xmax) * float(416) / float(w))
                temp_dic['ymax'] = int(int(ymax) * float(416) / float(h))
                temp_labelobj.append(temp_dic)




            label_percitra['object'] = temp_labelobj

        all_img.append(label_percitra)

    return all_img

class praposes_citra(object):
    def __init__(self):
        self.W_citra_reshape = 416
        self.H_citra_reshape = 416

    def get_lokasi_file(self, data_train):
        image_name = data_train['filename']
        return (image_name)

    def reshape_citra(self, data_train):
        image_name = self.get_lokasi_file(data_train)
        # print(image_name)
        image = cv2.imread(image_name)

        # get ukuran citra ori
        H_citra_ori, W_citra_ori, C_citra_ori = image.shape

        # reshape ukuran citra to 416x416
        image = cv2.resize(image, (self.H_citra_reshape, self.W_citra_reshape))

        # mengenbalikan urutan warna
        image = image[:, :, ::-1]

        # get dict
        all_objs = copy.deepcopy(data_train['object'])
        all_ground_truth = []
        for obj in all_objs:
            for attr in ['xmin', 'xmax']:
                # reshape value (penyesuaian ukuran) xmin sama xmax
                obj[attr] = int(int(obj[attr]) )
            for attr in ['ymin', 'ymax']:
                # reshape value (penyesuaian ukuran) ymin sama ymax
                obj[attr] = int(int(obj[attr]) )
            # xmin,ymin,xmax,ymax sudah dinormalisasi (/ukuran w,h asli citra ketika reshape)
            # /416 dinormalkan lagi,416 ukuran w,h citra stlh reshape

            xc = (obj['xmin'] + obj['xmax']) / 2
            yc = (obj['ymin'] + obj['ymax']) / 2
            wc = obj['xmax'] - obj['xmin']
            hc = obj['ymax'] - obj['ymin']

            all_ground_truth.append([xc, yc, wc, hc])

        return image, all_objs, all_ground_truth

class best_anchor(object):
    def get_best_anchor(list_ground_truth, matrix, grid_x, grid_y):
        # index list_ground_truth [xg,yg,wg,hg]
        temp_all_iou = []
        for anchor_i in range(len(ANCHOR_BOX)):
            # cek nilai obj anchor yg 0, jika != 0 maka pake anchor yang lain
            if matrix[grid_y, grid_x, anchor_i, 4] == 0:
                wg = list_ground_truth[2]
                hg = list_ground_truth[3]
                anchor_wg = ANCHOR_BOX[anchor_i][0]
                anchor_hg = ANCHOR_BOX[anchor_i][1]
                temp_all_iou.append(best_anchor.IOU([xg,yg,wg,hg], [0.5,0.5,anchor_wg,anchor_hg]))


            else:
                temp_all_iou.append(0)

        iou_terbaik = max(temp_all_iou)
        anchor_terbaik = temp_all_iou.index(iou_terbaik)
        # print("anchor terbaik ke",temp_all_iou.index(max(temp_all_iou)),"all iou",temp_all_iou,"anchor box yang dipakai",ANCHOR_BOX[temp_all_iou.index(max(temp_all_iou))])
        return anchor_terbaik, iou_terbaik

    def IOU(box1, box2):
        # index list_ground_truth [xg,yg,wg,hg]

        A_xmin = box1[0] - (box1[2] / 2)
        A_xmax = box1[0] + (box1[2] / 2)
        A_ymin = box1[1] - (box1[3] / 2)
        A_ymax = box1[1] + (box1[3] / 2)

        B_xmin = box2[0] - (box2[2] / 2)
        B_xmax = box2[0] + (box2[2] / 2)
        B_ymin = box2[1] - (box2[3] / 2)
        B_ymax = box2[1] + (box2[3] / 2)

        Box_Intersect_xmin = max(A_xmin, B_xmin)
        Box_Intersect_ymin = max(A_ymin, B_ymin)
        Box_Intersect_xmax = min(A_xmax, B_xmax)
        Box_Intersect_ymax = min(A_ymax, B_ymax)

        intersection_area = (max(Box_Intersect_xmin, Box_Intersect_xmax) - min(Box_Intersect_xmin,
                                                                               Box_Intersect_xmax)) * (
                                        max(Box_Intersect_ymin, Box_Intersect_ymax) - min(Box_Intersect_ymin,
                                                                                          Box_Intersect_ymax))
        object_area = box1[2] * box1[3]
        anchor_area = box2[2] * box2[3]
        union = object_area + anchor_area
        iou = intersection_area / (union - intersection_area)
        # print(iou,"iou",obj['wg'],obj['hg'],"ke",anchor_ke)

        return iou


class buat_data_target(object):
    def __init__(self, all_ground_truth, all_obj):
        self.size_grid = 416 / 13
        self.all_obj = all_obj
        self.all_ground_truth = all_ground_truth
        self.mapping_grid()



    def mapping_grid(self):
        temp_matrix = np.zeros((13, 13, len(ANCHOR_BOX), 5))
        a = 0
        for obj in self.all_ground_truth:
            # index list_ground_truth [xg,yg,wg,hg]



            # # get kordinat grid ----Cara Lama
            # xg = (obj[0] - grid_x * self.size_grid) / (self.size_grid - 1)
            # yg = (obj[1] - grid_y * self.size_grid) / (self.size_grid - 1)
            # wg = (obj[2] / 32)
            # hg = (obj[3] / 32)

            # get kordinat grid ---Cara Baru
            xg = (obj[0] / 32)
            yg = (obj[1] / 32)
            wg = (obj[2] / 32)
            hg = (obj[3] / 32)

            # get grid lokasi ke x y

            grid_x = int(np.floor(xg))
            grid_y = int(np.floor(yg))
            # get anchor, iuo
            anchor, iou = best_anchor.get_best_anchor([xg, yg, wg, hg], temp_matrix, grid_x, grid_y)

            # get delta_xywh  (Selisih antara x y w h anotasi - x y w h anchor box yang terpilih
            # x dan y anchorbox 0.5 karena berada di tengah grid
            # delta_x = xg - 0.5
            # delta_y = yg - 0.5
            # delta_w = (wg - ANCHOR_BOX[anchor][0]) / ANCHOR_BOX[anchor][0]
            # delta_h = (hg - ANCHOR_BOX[anchor][1]) / ANCHOR_BOX[anchor][1]

            temp_matrix[grid_y, grid_x, anchor, 4] = 1  # set 1 karena ada objek
            temp_matrix[grid_y, grid_x, anchor, 0] = xg
            temp_matrix[grid_y, grid_x, anchor, 1] = yg
            temp_matrix[grid_y, grid_x, anchor, 2] = wg
            temp_matrix[grid_y, grid_x, anchor, 3] = hg

            # HELP
            self.all_obj[a]['grid_x'] = grid_x
            self.all_obj[a]['grid_y'] = grid_y
            self.all_obj[a]['anchor'] = anchor
            self.all_obj[a]['xc'] = obj[0]
            self.all_obj[a]['yc'] = obj[1]
            self.all_obj[a]['wc'] = obj[2]
            self.all_obj[a]['hc'] = obj[3]
            self.all_obj[a]['xg'] = xg
            self.all_obj[a]['yg'] = yg
            self.all_obj[a]['wg'] = wg
            self.all_obj[a]['hg'] = hg
            # self.all_obj[a]['delta_x'] = delta_x
            # self.all_obj[a]['delta_y'] = delta_y
            # self.all_obj[a]['delta_w'] = delta_w
            # self.all_obj[a]['delta_h'] = delta_h
            a += 1

        return temp_matrix

import numpy as np
class Evaluasi(object):
    def __init__(self,prediksi,GT,treshold_iou=0.3):
        self.data_prediksi=self.parse_prediksi(prediksi)
        self.data_GT = self.parse_GT(GT)
        self.treshold_iou=treshold_iou
        self.finder()
        # print(self.data_GT)
        # print(self.data_prediksi)
        # print(self.finder())

    def IOU(self,A, B):

        # index list_ground_truth [xg,yg,wg,hg]

        A_xmin = A[0]
        A_xmax = A[2]
        A_ymin = A[1]
        A_ymax = A[3]

        B_xmin = B[0]
        B_xmax = B[2]
        B_ymin = B[1]
        B_ymax = B[3]
        # print(A_xmin,A_ymin,A_xmax,A_ymax)
        # print(B_xmin,B_ymin,B_xmax,B_ymax)

        Box_Intersect_xmin = max(A_xmin, B_xmin)
        Box_Intersect_ymin = max(A_ymin, B_ymin)
        Box_Intersect_xmax = min(A_xmax, B_xmax)
        Box_Intersect_ymax = min(A_ymax, B_ymax)
        # print(Box_Intersect_xmin,Box_Intersect_ymin,Box_Intersect_xmax,Box_Intersect_ymax)

        if Box_Intersect_xmax < Box_Intersect_xmin or Box_Intersect_ymax < Box_Intersect_ymin :
            return 0

        else:

            intersection_area = (max(Box_Intersect_xmin, Box_Intersect_xmax) - min(Box_Intersect_xmin,
                                                                               Box_Intersect_xmax)) * (
                                    max(Box_Intersect_ymin, Box_Intersect_ymax) - min(Box_Intersect_ymin,
                                                                                      Box_Intersect_ymax))
            W_A = A_xmax - A_xmin
            H_A = A_ymax - A_ymin
            W_B = B_xmax - B_xmin
            H_B = B_ymax - B_ymin

            object_area = W_A * H_A
            anchor_area = W_B * H_B
            union = object_area + anchor_area
            iou = intersection_area / (union - intersection_area)

            return iou

    def parse_prediksi(self,data_prediksi):
        temp_prediksi=[]
        for data in data_prediksi:
            if [data['xmin'],data['ymin'],data['xmax'],data['ymax']] not in temp_prediksi:

                temp_prediksi.append([data['xmin'],data['ymin'],data['xmax'],data['ymax']])
        return temp_prediksi

    def parse_GT(self, data_GT):
        temp_GT = []
        for data in data_GT['object']:
            temp_GT.append([data['xmin'], data['ymin'], data['xmax'], data['ymax']])
        return temp_GT

    def finder(self):
        prediksi=self.data_prediksi
        GT=self.data_GT

        temp_data=np.zeros((len(GT),len(prediksi)))
        # print(temp_data.shape,len(GT),len(prediksi))

        #calc nilai iou dr GT ke all prediksi
        for GT_i in range(len(GT)):
            for pred_i in range(len(prediksi)):
                iou=self.IOU(prediksi[pred_i],GT[GT_i])

                # print(pred_i,GT_i,prediksi[pred_i],GT[GT_i],iou)
                if iou > self.treshold_iou:
                    temp_data[GT_i,pred_i]=iou



        TP=0
        FP=0
        # print(temp_data)
        list_pred_TP=np.where(temp_data.any(axis=0))[0]
        #find True Postif (len data column np not contain all 0)
        TP=len(list_pred_TP)

        # matiin jika len TP > lebih dari len GT ex, TP=3 pdhl GT=1 krn akan menambah nilai f1-score and precision
        if TP > len(GT):
            TP=len(GT)

        #find FP (len prediksi - TP)
        FP=len(prediksi)-TP

        FN=0
        #FN (==0 if len(GT) < len (prediksi)
        #else
        if len(GT) > TP:
            FN = len(GT)-TP

        # print(TP,FP,FN)
        data_eval={'TP':TP,'FP':FP,'FN':FN}


        # print(data_eval)
        self.data_iou=temp_data
        return data_eval


    def get_precision(self):
        data=self.finder()#return value {'TP': 0, 'FP': 1, 'FN': 3}
        TP=data['TP']
        FP = data['FP']
        FN = data['FN']


        if TP ==0:
            precision= 0
        else:
            precision=TP/(TP+FP)
        return precision

    def get_recall(self):
        data=self.finder()#return value {'TP': 0, 'FP': 1, 'FN': 3}
        TP=data['TP']
        FP = data['FP']
        FN = data['FN']


        if TP ==0:
            recall= 0.0
        else:
            recall=TP/(TP+FN)
        return recall

    def get_accuracy(self):
        data=self.finder()#return value {'TP': 0, 'FP': 1, 'FN': 3}
        TP=data['TP']
        FP = data['FP']
        FN = data['FN']

        if TP ==0:
            accuracy= 0.0
        else:
            accuracy=TP/(TP+FP+FN)
        return accuracy

    def get_f1score(self):
        data = self.finder()  # return value {'TP': 0, 'FP': 1, 'FN': 3}

        if data['TP']  ==0:

            f1score= 0.0
        else:
            f1score = (2 * self.get_recall() * self.get_precision()) / (self.get_recall() + self.get_precision())
        return f1score

# print(sorted(data.items(),reverse=True))
class NMS(object):
    def __init__(self,data,max_putbbox_from_sort_high_prob=None,merge_nms=True,merge_berulang=True):
        self.data=data
        self.merge_nms=merge_nms
        self.merge_berulang=merge_berulang
        self.limit=max_putbbox_from_sort_high_prob

    def sort_best_conf(self):
        self.data_sort=sorted(self.data.items(),reverse=True)
        return self.data_sort
    def IOU(self,A, B):
        # index list_ground_truth [xg,yg,wg,hg]

        A_xmin = A[0]
        A_xmax = A[2]
        A_ymin = A[1]
        A_ymax = A[3]

        B_xmin = B[0]
        B_xmax = B[2]
        B_ymin = B[1]
        B_ymax = B[3]
        # print(A_xmin,A_ymin,A_xmax,A_ymax)
        # print(B_xmin,B_ymin,B_xmax,B_ymax)

        Box_Intersect_xmin = max(A_xmin, B_xmin)
        Box_Intersect_ymin = max(A_ymin, B_ymin)
        Box_Intersect_xmax = min(A_xmax, B_xmax)
        Box_Intersect_ymax = min(A_ymax, B_ymax)
        # print(Box_Intersect_xmin,Box_Intersect_ymin,Box_Intersect_xmax,Box_Intersect_ymax)

        if Box_Intersect_xmax < Box_Intersect_xmin or Box_Intersect_ymax < Box_Intersect_ymin :
            return 0

        else:
            intersection_area = (max(Box_Intersect_xmin, Box_Intersect_xmax) - min(Box_Intersect_xmin,
                                                                                   Box_Intersect_xmax)) * (
                                        max(Box_Intersect_ymin, Box_Intersect_ymax) - min(Box_Intersect_ymin,
                                                                                          Box_Intersect_ymax))
            W_A = A_xmax - A_xmin
            H_A = A_ymax - A_ymin
            W_B = B_xmax - B_xmin
            H_B = B_ymax - B_ymin

            object_area = W_A * H_A
            anchor_area = W_B * H_B
            union = object_area + anchor_area
            iou = intersection_area / (union - intersection_area)

            return iou



    def calc(self):
        self.data_sort=self.sort_best_conf()
        list_bbox=[]

        for data in self.data_sort:
           list_bbox.append(data[1])

        if self.limit==None:
            return list_bbox

        else:
            return list_bbox[:self.limit]




    def pred(self,threshold=0.5):
        list_bbox=self.calc()

        temp={}
        for i in range(len(list_bbox)):
            temp[i]=1 #set 1 semua jika tampil,0 jika tdk tampil

        for i in range (len(list_bbox)):
            # temp[i] = 0
            box_a=list_bbox[i]
            for j in range(i+1,len(list_bbox)):


                box_b = list_bbox[j]

                if i==j or temp[j]==0:
                    continue
                else:
                    iou=self.IOU(box_a,box_b)

                    if iou > threshold:

                        temp[j] = 0 #bbox tdk ditampilkan / dihapus

        temp_box=[] #cek dan ambil yg nilai 1
        for i in temp.keys():
            if temp[i]==1:
              temp_box.append(list_bbox[i])

        # print(temp_box)
        #update hasil merge

        if self.merge_nms==True:
            temp_box=self.merge(temp_box)


        temp_all_box = []

        for i in range(len(temp_box)):
            temp_dic = {}
            temp_dic['xmin'] = temp_box[i][0]
            temp_dic['ymin'] = temp_box[i][1]
            temp_dic['xmax'] = temp_box[i][2]
            temp_dic['ymax'] = temp_box[i][3]
            temp_dic['obj'] = self.data_sort[i][0]
            temp_all_box.append(temp_dic)

        return temp_all_box
        #
        # fig, ax = plt.subplots(1)
        # for i in range(len(temp)):
        #     if temp[i]==1:
        #
        #         rec = patches.Rectangle((list_bbox[i][0], list_bbox[i][1]), list_bbox[i][2] - list_bbox[i][0], list_bbox[i][3] - list_bbox[i][1],
        #                         linewidth=2, edgecolor='green', facecolor='none')
        #         ax.add_patch(rec)

        # return temp


    def merge(self,  temp_box,theshold_merge=.0):
        ULANGI=True
        def hapus_duplikat(list_a):

            list = list_a.copy()
            for i in list:
                count = 0
                for j in list_a:
                    if j == i:

                        count += 1
                        if count > 1:
                            list_a.remove(j)

            return list_a
        # print((temp_box),"Aaa")


        temp_index={}
        for index_i in range(len(temp_box)):
            temp_for_every_index=[]
            for index_j in range(len(temp_box)):
                if index_j != index_i:
                    iou=self.IOU(temp_box[index_i],temp_box[index_j])
                    if iou > theshold_merge:
                        temp_for_every_index.append(index_j)

            temp_index[index_i]=temp_for_every_index


        # print(temp_box)
        # print(temp_index)#hasil {0: [5], 1: [2, 9], 2: [1, 9], 3: [5] dll


        #cek node data,ex b1=b2,b4 dll
        # hasil {0: [], 1: [5], 2: [3], 3: [2, 7], 4: [5], 5: [1, 4, 6], 6: [5], 7: [3]}


        new_bbox=[]
        for index_i in temp_index.keys():
           if temp_index[index_i] == []:


               # nyalain kalo box yang gada temennya di keep / tetap di tampilin
               new_bbox.append([index_i])
               # continue
           else:
               a=[index_i]
               for index_j in temp_index[index_i]:
                  a.append(index_j)

               new_bbox.append(sorted(a))



        #hapus duplikat data
        # print(new_bbox,"s")
        new_bbox = hapus_duplikat(new_bbox)
        a_new_bbox=new_bbox

        # gabung data cek subset to superset
        # hasil [[0], [3, 2, 7], [5, 1, 4, 6]]
        # print(new_bbox)
        for data in (new_bbox):

            for data_pembanding in (new_bbox):
                if data != data_pembanding:
                    # print(data,data_pembanding,"Aa")

                    if set(data_pembanding).issubset(data) == True  :
                        if data_pembanding in a_new_bbox:
                            a_new_bbox.remove(data_pembanding)

                    elif set(data_pembanding).issuperset(data) == True:
                        if data in a_new_bbox:
                            a_new_bbox.remove(data)

            # hapus duplikat data
        # a_new_bbox = hapus(a_new_bbox)
        # print(a_new_bbox)

        if len(a_new_bbox)==len(temp_box):
            ULANGI=False

        def merge_bbox(A,B):
            A_xmin = A[0]
            A_xmax = A[2]
            A_ymin = A[1]
            A_ymax = A[3]

            B_xmin = B[0]
            B_xmax = B[2]
            B_ymin = B[1]
            B_ymax = B[3]
            # print(A_xmin,A_ymin,A_xmax,A_ymax)
            # print(B_xmin,B_ymin,B_xmax,B_ymax)

            Box_Intersect_xmin = min(A_xmin, B_xmin)
            Box_Intersect_ymin = min(A_ymin, B_ymin)
            Box_Intersect_xmax = max(A_xmax, B_xmax)
            Box_Intersect_ymax = max(A_ymax, B_ymax)

            return [Box_Intersect_xmin,Box_Intersect_ymin,Box_Intersect_xmax,Box_Intersect_ymax]

        #merge bbox jika ada
        a=[]
        for bbox_i in a_new_bbox:
            if len(bbox_i) > 1:

                temp=temp_box[bbox_i[0]]
                for j in range (1,len(bbox_i)):
                    temp=merge_bbox(temp,temp_box[bbox_i[j]])

                a.append(temp)

            else:
                a.append(temp_box[bbox_i[0]])


        #return from merge berupa[xmin,ymin,xmax,ymax]
        # print(a,"A")

        if ULANGI==True and self.merge_berulang==True:
            return self.merge(a)
        else:

            return a


    def nms(self, threshold=.2):
        detections= self.calc()
        detections = sorted(detections, key=lambda detections: detections[2],
                            reverse=True)

        new_detections = []

        new_detections.append(detections[0])

        del detections[0]

        for index, detection in enumerate(detections):
            for new_detection in new_detections:
                if self.IOU(detection, new_detection) > threshold:
                    del detections[index]
                    break
            else:
                new_detections.append(detection)
                del detections[index]

        # fig, ax = plt.subplots(1)
        # list_bbox=new_detections
        # for i in range(len(new_detections)):
        #
        #      rec = patches.Rectangle((list_bbox[i][0], list_bbox[i][1]), list_bbox[i][2] - list_bbox[i][0],
        #                                 list_bbox[i][3] - list_bbox[i][1],
        #                                 linewidth=2, edgecolor='blue', facecolor='none')
        #      ax.add_patch(rec)
        temp_box=new_detections
        temp_all_box = []
        for i in range(len(temp_box)):
            temp_dic = {}
            temp_dic['xmin'] = temp_box[i][0]
            temp_dic['ymin'] = temp_box[i][1]
            temp_dic['xmax'] = temp_box[i][2]
            temp_dic['ymax'] = temp_box[i][3]
            temp_dic['obj'] = self.data_sort[i][0]
            temp_all_box.append(temp_dic)

        return temp_all_box
        # return new_detections

    def non_max_suppression_fast(self, overlapThresh=.4):
        # if there are no boxes, return an empty list
        box=self.calc()
        # print(len(box))
        boxes=np.array(box)

        if len(boxes) == 0:
            return []
        # if the bounding boxes integers, convert them to floats --
        # this is important since we'll be doing a bunch of divisions

        if boxes.dtype.kind == "i":
            boxes = boxes.astype("float")
            #
            # initialize the list of picked indexes
        pick = []

        # grab the coordinates of the bounding boxes
        x1 = boxes[:, 0]
        y1 = boxes[:, 1]
        x2 = boxes[:, 2]
        y2 = boxes[:, 3]
        # compute the area of the bounding boxes and sort the bounding
        # boxes by the bottom-right y-coordinate of the bounding box

        area = (x2 - x1 + 1) * (y2 - y1 + 1)
        idxs = np.argsort(y2)
        # keep looping while some indexes still remain in the indexes
        # list
        while len(idxs) > 0:
            # grab the last index in the indexes list and add the
            # index value to the list of picked indexes
            last = len(idxs) - 1
            i = idxs[last]
            pick.append(i)
            # find the largest (x, y) coordinates for the start of
            # the bounding box and the smallest (x, y) coordinates
            # for the end of the bounding box
            xx1 = np.maximum(x1[i], x1[idxs[:last]])
            yy1 = np.maximum(y1[i], y1[idxs[:last]])
            xx2 = np.minimum(x2[i], x2[idxs[:last]])
            yy2 = np.minimum(y2[i], y2[idxs[:last]])
            # compute the width and height of the bounding box
            w = np.maximum(0, xx2 - xx1 + 1)
            h = np.maximum(0, yy2 - yy1 + 1)
            # compute the ratio of overlap
            overlap = (w * h) / area[idxs[:last]]
            # delete all indexes from the index list that have
            idxs = np.delete(idxs, np.concatenate(([last],
                                                   np.where(overlap > overlapThresh)[0])))
        # return only the bounding boxes that were picked using the
        # integer data type
        # temp= boxes[pick]
        # fig, ax = plt.subplots(1)
        # list_bbox = boxes[pick]
        # for i in range(len(list_bbox)):
        #     rec = patches.Rectangle((list_bbox[i][0], list_bbox[i][1]), list_bbox[i][2] - list_bbox[i][0],
        #                             list_bbox[i][3] - list_bbox[i][1],
        #                             linewidth=2, edgecolor='blue', facecolor='none')
        #     ax.add_patch(rec)
        temp_box=boxes[pick]
        if self.merge_nms==True:
            temp_box=self.merge(temp_box)
        temp_all_box=[]
        for i in range (len(temp_box)):
            temp_dic = {}
            temp_dic['xmin'] = temp_box[i][0]
            temp_dic['ymin'] = temp_box[i][1]
            temp_dic['xmax'] = temp_box[i][2]
            temp_dic['ymax'] = temp_box[i][3]
            temp_dic['obj'] = self.data_sort[i][0]
            temp_all_box.append(temp_dic)


        return temp_all_box
        # return boxes[pick]



class YOLOv2(object):
    def __init__(self, file, tipe_model, max_bbox, treshold_obj=0.5, treshold_eval=0.5, treshold_nms=0.5,
                 norm=False, merge=True):
        url_gambar = file['filename']
        self.max_bbox_limit_fromtop = max_bbox
        self.n_grid = 13
        self.Treshold_obj = treshold_obj
        self.Treshold_eval = treshold_eval
        self.Treshold_nms = treshold_nms
        self.Norm = norm
        self.merge_nms = merge
        self.tipe_model = tipe_model
        self.H_citra_reshape = 416
        self.W_citra_reshape = 416
        self.url_gambar = url_gambar
        self.data = self.get_output()

        self.data_eval = Evaluasi(self.konversi_balik(self.data), file, treshold_iou=self.Treshold_eval)
        self.get_f1score = self.data_eval.get_f1score()

        print(self.data_eval.data_iou, "\nhasil :", self.data_eval.finder(), "\nprecision :",
              self.data_eval.get_precision(), "\nrecall :", self.data_eval.get_recall(), "\naccuracy :",
              self.data_eval.get_accuracy(), "\nf1-score :", self.data_eval.get_f1score())

        self.draw(self.konversi_balik(self.data), file)

    def get_output(self):
        image = cv2.imread(self.url_gambar)
        image = cv2.resize(image, (self.H_citra_reshape, self.W_citra_reshape))
        image = image / 255
        # membaguskan citra asal
        if self.Norm == True:
            image = image[:, :, ::-1]

        model = tf.keras.models.load_model(self.tipe_model, compile=False)

        hasil_matrix = model.predict(image.reshape(1,self.H_citra_reshape, self.W_citra_reshape, 3))

        if hasil_matrix.shape[4] == 5:
            hasil_matrix = hasil_matrix.reshape(self.n_grid, self.n_grid, len(ANCHOR_BOX), 5)
        else:
            hasil_matrix = hasil_matrix.reshape(self.n_grid, self.n_grid, len(ANCHOR_BOX), 5 + 20)
        return hasil_matrix

    def sigmoid(self, x):
        return 1. / (1. + np.exp(-x))

    def softmax(self, x):
        return np.exp(x) / np.sum(np.exp(x), axis=0)

    def konversi_balik(self, data):

        temp_label_objek = []
        temp_label_objek_for_nms = {}
        obj = 1
        for baris in range(self.n_grid):
            for kolom in range(self.n_grid):
                for anchor_i in range(len(ANCHOR_BOX)):
                    # print(baris,kolom,anchor_i,data[baris,kolom,anchor_i,4],"sig",self.sigmoid(data[baris,kolom,anchor_i,4]),data[baris,kolom,anchor_i])

                    a = float(self.sigmoid(data[baris, kolom, anchor_i, 4]))
                    box_probs = a
                    if box_probs > self.Treshold_obj:

                        # print("objek :",obj,"iou :",self.sigmoid(data[baris][kolom][anchor_i][0]),"grid_x :",baris,"grid_y :",kolom)
                        # obj+=1
                        # get bounding box dari numpy pada masing* anchor
                        xg = data[baris][kolom][anchor_i][0]
                        yg = data[baris][kolom][anchor_i][1]
                        wg = data[baris][kolom][anchor_i][2]
                        hg = data[baris][kolom][anchor_i][3]

                        temp_dic = {}

                        # konversi ke kordinat anotasi
                        x_predict = self.sigmoid(xg) * 31 + kolom * 32
                        y_predict = self.sigmoid(yg) * 31 + baris * 32
                        w_predict = math.exp(wg) * ANCHOR_BOX[anchor_i][0] * 32
                        h_predict = math.exp(hg) * ANCHOR_BOX[anchor_i][1] * 32

                        # get x,y min max
                        temp_dic['xmin'] = x_predict - (w_predict / 2)
                        temp_dic['ymin'] = y_predict - (h_predict / 2)
                        temp_dic['xmax'] = x_predict + (w_predict / 2)
                        temp_dic['ymax'] = y_predict + (h_predict / 2)
                        temp_dic['obj'] = self.sigmoid(data[baris][kolom][anchor_i][4])

                        if temp_dic['xmin'] > 0 and temp_dic['xmax'] > 0 and temp_dic['ymin'] > 0 and temp_dic[
                            'ymax'] > 0 and temp_dic[
                            'ymax'] < 416 and temp_dic['xmax'] < 416:
                            temp_label_objek.append(temp_dic)
                            # print(temp_dic)
                            temp_label_objek_for_nms[box_probs] = [temp_dic['xmin'], temp_dic['ymin'], temp_dic['xmax'],
                                                                   temp_dic['ymax']]

                            # temp_label_objek_for_nms[a]=[temp_dic['xmin'],temp_dic['ymin'],temp_dic['xmax'],temp_dic['ymax']]
                            # print("objek :",obj,"iou :",self.sigmoid(data[baris][kolom][anchor_i][0]),"/",(data[baris][kolom][anchor_i][0]),"grid_x :",baris,"grid_y :",kolom)
                            # obj += 1
        # print(temp_label_objek_for_nms)
        nms = NMS(temp_label_objek_for_nms, self.max_bbox_limit_fromtop,
                  self.merge_nms)  # 10== max bounding box yang diambil dari urutan terbesar
        bbox_nms = (nms.pred(self.Treshold_nms))
        bbox_nms=(nms.non_max_suppression_fast(self.Treshold_nms))

        # return temp_label_objek
        return bbox_nms

    def draw(self, temp_anotasi_mentah, obj_asli):
        image_name = self.url_gambar
        print(image_name)
        image = cv2.imread(image_name)
        H_citra_ori, W_citra_ori, C_citra_ori = image.shape
        image = cv2.resize(image, (self.H_citra_reshape, self.W_citra_reshape))
        # membaguskan citra asal
        image = image[:, :, ::-1]

        # draw grid
        fig, ax = plt.subplots(1)
        for grid_y in range(0, 416, 32):
            for grid_x in range(0, 416, 32):
                rec = patches.Rectangle((grid_x, grid_y), 32, 32
                                        , linewidth=0.5, edgecolor='black', facecolor='none')
                ax.add_patch(rec)

        # draw bbox dr data target
        a = 1
        color_i = ['red', 'darkred', 'indianred', 'crimson', 'tomato', 'orangered']
        for obj in (temp_anotasi_mentah):
            if obj['xmin'] > 0 and obj['xmax'] > 0 and obj['ymin'] > 0 and obj['ymax'] > 0 and obj['ymax'] < 416 and \
                    obj['xmax'] < 416:
                rec = patches.Rectangle((obj['xmin'], obj['ymin']), obj['xmax'] - obj['xmin'],
                                        obj['ymax'] - obj['ymin'], linewidth=2, edgecolor=color_i[a % len(color_i)],
                                        facecolor='none')
                # a=round(obj['obj'],2)
                # plt.text((obj['xmax']+obj['xmin'])/2, obj['ymax']-2, a,
                #          color='black',backgroundcolor=color_i[a%len(color_i)])

                ax.add_patch(rec)
                # print(a, ">>", obj)
                a += 1

        # asli
        for obj in (obj_asli['object']):
            rec = patches.Rectangle((obj['xmin'], obj['ymin']), obj['xmax'] - obj['xmin'], obj['ymax'] - obj['ymin'],
                                    linewidth=2, edgecolor='green', facecolor='none')
            ax.add_patch(rec)

        plt.imshow(image)



def custom_loss_2(y_true, y_pred):
    #get len grid
    # output 13 as grid (biar flexibel)
    n_cells = y_pred.get_shape().as_list()[1]

    #ytrue and ypred every batch
    y_true = tf.reshape(y_true, tf.shape(y_pred), name='y_true')
    y_pred = tf.identity(y_pred, name='y_pred')

    # numpy buat nampung x-y pred, shape = batch_size,grid,grid,2(x,y)
    predicted_xy = tf.nn.sigmoid(y_pred[..., :2])

    # set value xy mengikuti grid x dan y
    cell_inds = tf.range(n_cells, dtype=tf.float64)
    # cell_inds output [ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12.]

    # set value xy mengikuti nilai grid x dan y sesuai urutan vector (selalu berada pada pusat grid) misal, berada di grid 0 maka set nilai 0.5 dst samapi 12.5
    '''contoh [batch_i][5 as y][7 as x] output 
    [[7.5 5.5]
     [7.5 5.5]
     [7.5 5.5]
     [7.5 5.5]
     [7.5 5.5]] predicted_xy'''
    predicted_xy = tf.stack((
        predicted_xy[..., 0] + tf.reshape(cell_inds, [1, -1, 1]),
        predicted_xy[..., 1] + tf.reshape(cell_inds, [-1, 1, 1])
    ), axis=-1)


    # set value wh dimana 5 nilai wh pada semua anchor di grid mengikuti nilai anchor sesuai urutan
    '''contoh [batch_i][5 as y][6 as x] output  [[5.42265442e+110 2.39281903e+133]
 [1.26952956e+000 4.57130596e+000]
 [4.34356520e+000 9.05625981e+000]
 [1.77578193e+000 6.61574849e+000]
 [7.82103790e-001 2.89223844e+000]] predicted_wh'''
    # predicted_wh = ANCHOR_BOX * tf.exp(y_pred[..., 2:4])
    predicted_wh = ANCHOR_BOX * tf.exp(y_pred[..., 2:4])



    # get nilai predict min dan max untuk proses iou antara prediksi dengan ground truth
    predicted_min = predicted_xy - predicted_wh / 2
    predicted_max = predicted_xy + predicted_wh / 2

    #get nilai objectnes pada setiap grid anchor predicted_objectedness bernilai 0.5 karena hasil sigmoid(0)
    '''contoh [batch_i][5 as y][6 as x] output
    0.73105858 0.5        0.5        0.5        0.5       ] predicted_objectedness'''
    predicted_objectedness = tf.nn.sigmoid(y_pred[..., 4])

    #get xy ground truth
    true_xy = y_true[..., :2]
    # get wh ground truth
    true_wh = y_true[..., 2:4]

    # get nilai true min dan max dari ground truth untuk proses iou  ground truth dgn prediksi
    true_min = true_xy - true_wh / 2
    true_max = true_xy + true_wh / 2



    # get iou antra ground truth dengan prediksi, untuk set nilai objectnes
    intersect_mins = tf.maximum(predicted_min, true_min)
    intersect_maxes = tf.minimum(predicted_max, true_max)
    intersect_wh = tf.maximum(intersect_maxes - intersect_mins, 0.)
    intersect_areas = intersect_wh[..., 0] * intersect_wh[..., 1]

    true_areas = true_wh[..., 0] * true_wh[..., 1]
    pred_areas = predicted_wh[..., 0] * predicted_wh[..., 1]

    union_areas = pred_areas + true_areas - intersect_areas
    #get IOU score tiap anchor
    '''contoh [batch_i][5 as y][6 as x] output [5.97051471e-240 0.00000000e+000 0.00000000e+000 0.00000000e+000
 0.00000000e+000] iou_scores'''
    iou_scores = intersect_areas / union_areas

    #get nilai objectnes dari ground truth setiap anchor
    responsibility_selector = y_true[..., 4] 

    #vetcor nilai loss xy prediksi, dimana jika objectnes anchor =1 maka akan memiliki nilai loss xy, namun jika objectnes anchor =0 maka memiliki nilai 0
    ''' [[24336.  2601.]
  [    0.     0.]
  [    0.     0.]
  [    0.     0.]
  [    0.     0.]]'''
    xy_diff = tf.square(true_xy - predicted_xy) * responsibility_selector[..., None]
    #total xy loss dalam 1 citra
    xy_loss = tf.reduce_sum(xy_diff, axis=[1, 2, 3, 4])

  #   # vetcor nilai loss wh prediksi, dimana jika objectnes anchor =1 maka akan memiliki nilai loss wh, namun jika objectnes anchor =0 maka memiliki nilai 0
  #   '''[[5.42265442e+110 2.39281903e+133]
  # [0.00000000e+000 0.00000000e+000]
  # [0.00000000e+000 0.00000000e+000]
  # [0.00000000e+000 0.00000000e+000]
  # [0.00000000e+000 0.00000000e+000]]'''
  #   wh_diff = tf.square(tf.sqrt(true_wh) - tf.sqrt(predicted_wh)) * responsibility_selector[..., None]
  #   # total wh loss dalam 1 citra
  #   wh_loss = tf.reduce_sum(wh_diff, axis=[1, 2, 3, 4])

    # vetcor nilai loss objek prediksi, dimana jika objectnes anchor =1 maka akan memiliki nilai loss objek, namun jika objectnes anchor =0 maka memiliki nilai 0
    '''[[0.         0.         0.         0.         0.        ]
 [0.         0.         0.         0.         0.        ]
 [0.         0.         0.         0.         0.        ]
 [0.         0.         0.         0.         0.        ]
 [0.         0.         0.         0.         0.        ]
 [0.         0.         0.         0.         0.        ]
 [0.53444665 0.         0.         0.         0.        ]
 [0.         0.         0.         0.         0.        ]
 [0.         0.         0.         0.         0.        ]
 [0.         0.         0.         0.         0.        ]
 [0.         0.         0.         0.         0.        ]
 [0.         0.         0.         0.         0.        ]
 [0.         0.         0.         0.         0.        ]]'''
    obj_diff = tf.square(iou_scores - predicted_objectedness) * responsibility_selector
    # total obj loss dalam 1 citra
    obj_loss = tf.reduce_sum(obj_diff, axis=[1, 2, 3])

    #get best iou tiap grid dari seluruh anchor
    '''contoh [batch_i][5 as y] output [0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000
 0.00000000e+000 0.00000000e+000 5.97051471e-240 0.00000000e+000
 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000
 0.00000000e+000]'''
    best_iou = tf.reduce_max(iou_scores, axis=-1)

    #bantuan jika grid memiliki nilai iou diatas treshold maka nilai vektor temp grid nilai 0, jika lebih dibawah treshold bernilai1, bantuan buat perkalia itung no object loss
    '''grid x 8  grid y 6 ada iou > theshold
    [[1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [0.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]
 [1.]]'''
    temp=tf.compat.v1.to_float(best_iou < 0.5)[..., None]
    temp_2=tf.cast(temp, dtype=tf.float64)
    # vector nilai loss no_obj , dimana jika objectnes anchor =1 maka akan memiliki nilai 0 loss no obj, namun jika objectnes anchor =0 maka memiliki nilai loss 0.25
    '''[[0.25 0.25 0.25 0.25 0.25]
 [0.25 0.25 0.25 0.25 0.25]
 [0.25 0.25 0.25 0.25 0.25]
 [0.25 0.25 0.25 0.25 0.25]
 [0.25 0.25 0.25 0.25 0.25]
 [0.25 0.25 0.25 0.25 0.25]
 [0.   0.25 0.25 0.25 0.25]
 [0.25 0.25 0.25 0.25 0.25]
 [0.25 0.25 0.25 0.25 0.25]
 [0.25 0.25 0.25 0.25 0.25]
 [0.25 0.25 0.25 0.25 0.25]
 [0.25 0.25 0.25 0.25 0.25]
 [0.25 0.25 0.25 0.25 0.25]]'''
    #(1 - responsibility_selector) membuat nilai loss no obj 0 jika GT=1 karena (1 - responsibility_selector(GT)(0/1)),
    no_obj_diff = tf.square(0 - predicted_objectedness) * temp_2 * (1 - responsibility_selector)
    #total all vector no obj
    no_obj_loss = tf.reduce_sum(no_obj_diff, axis=[1, 2, 3])


    #Total all LOSS
    loss = object_coord_scale * (xy_loss) + object_conf_scale * obj_loss + noobject_conf_scale * no_obj_loss


    '''
    Kesimpulan :
    1.nilai prediksi x dan y diset 0-12 mengkuti vektor jumlah grid,
    2.nilai prediksi w dan h (tiap anchor) pada masing masing grid mengikuti nilai anchor yang dibuat ketika training sesuai urutan
    3.
    '''


    # # initialize the variable, turn off ketika training
    # init_op = tf.compat.v1.initialize_all_variables()

    # with tf.compat.v1.Session() as sess:
    #     sess.run(init_op)  # execute init_op
    #     # print the random values that we sample
    #     print(sess.run(true_xy[0][8][6]),"true_xy")
    #     print(sess.run(true_wh[0][8][6]),"true_wh")
    #     print(sess.run(true_min[0][8][6]), "true_min")
    #     print(sess.run(true_max[0][8][6]), "true_max")
    #     print(sess.run(true_areas[0][8][6]),"true_areas")

    #     # print(sess.run(cell_inds))
    #     # print(sess.run(y_pred[0][5][6]))
    #     print(sess.run(intersect_areas[0][8][6]),"intersect_areas")
    #     print(sess.run(intersect_mins[0][8][6]),"intersect_min")
    #     print(sess.run(intersect_maxes[0][8][6]),"intersect_max")

    #     print(sess.run(predicted_objectedness[0][8][6]),"predicted_objectedness")
    #     print(sess.run(predicted_min[0][8][6]), "predicted_min")
    #     print(sess.run(predicted_max[0][8][6]), "predicted_max")
    #     print(sess.run(pred_areas[0][8][6]),"pred_areas")
    #     print(sess.run(iou_scores[0][8][6]),"iou_scores")


    #     print(sess.run(best_iou[0][8]),"best_iou")
    #     print(sess.run(temp_2[0][8]),"temp2")

    #     print(sess.run(predicted_xy[0][8][6]),"predicted_xy")
    #     print(sess.run(predicted_wh[0][8][6]),"predicted_wh")
    #     print(sess.run(xy_loss),"xy_loss")
    #     print(sess.run(xy_diff[0][8]),"xy_diff")
    #     # print(sess.run(wh_loss),"wh_loss")
    #     # print(sess.run(wh_diff[0][8]),"wh_diff")
    #     print(sess.run(obj_loss),"obj_loss")
    #     print(sess.run(obj_diff[0][8]),"obj_diff")
    #     print(sess.run(no_obj_loss),"no obj_loss")
    #     print(sess.run(no_obj_diff[0][8]),"no obj_diff")

    #     print(sess.run(loss))

    return loss

class YOLOv2_Citra(object):
    def __init__(self, file, tipe_model, max_bbox, treshold_obj=0.5, treshold_nms=0.5,
                 norm=False, merge=True):
        img_inp = '/content/drive/My Drive/KULIAH/TA/PROGRAM/dataset/Citra Test/' + str(file)
        img_out = '/content/drive/My Drive/KULIAH/TA/PROGRAM/dataset/Citra Test/citra_output.jpg'
        self.H_citra_reshape = 416
        self.W_citra_reshape = 416
        # new_model.summary()
        # new_model.load_weights(tipe_model)


        image = cv2.imread(img_inp)
        frame_h,frame_w,channel= image.shape
        self.scale_h = frame_h / self.H_citra_reshape
        self.scale_w = frame_w / self.W_citra_reshape

        self.max_bbox_limit_fromtop = max_bbox
        self.n_grid = 13
        self.Treshold_obj = treshold_obj

        self.Treshold_nms = treshold_nms
        self.Norm = norm
        self.merge_nms = merge
        self.tipe_model = tipe_model
        self.H_citra_reshape = 416
        self.W_citra_reshape = 416

        data = self.get_output(image)
        boxes = self.konversi_balik(data)
        image = self.draw_citra(image, boxes)
        # cv2.imwrite(img_out, image)
        cv2_imshow(image)
        cv2.waitKey(0)

    def get_output(self, image):
        image = cv2.resize(image, (self.H_citra_reshape, self.W_citra_reshape))
        image = image / 255
        # membaguskan citra asal
        if self.Norm == True:
            image = image[:, :, ::-1]

        if self.tipe_model==path_model_20:
            model=model_ori(self.tipe_model)
        else:
            model = tf.keras.models.load_model(self.tipe_model, compile=False)


        hasil_matrix = model.predict(image.reshape(1, self.H_citra_reshape, self.W_citra_reshape, 3))
        tf.keras.backend.clear_session()

        if hasil_matrix.shape[4] == 5:
            hasil_matrix = hasil_matrix.reshape(self.n_grid, self.n_grid, len(ANCHOR_BOX), 5)
        else:
            hasil_matrix = hasil_matrix.reshape(self.n_grid, self.n_grid, len(ANCHOR_BOX), 5 + 20)
        return hasil_matrix

    def sigmoid(self, x):
        return 1. / (1. + np.exp(-x))

    def softmax(self, x):
        return np.exp(x) / np.sum(np.exp(x), axis=0)

    def konversi_balik(self, data):

        temp_label_objek = []
        temp_label_objek_for_nms = {}
        obj = 1
        for baris in range(self.n_grid):
            for kolom in range(self.n_grid):
                for anchor_i in range(len(ANCHOR_BOX)):
                    # print(baris,kolom,anchor_i,data[baris,kolom,anchor_i,4],"sig",self.sigmoid(data[baris,kolom,anchor_i,4]),data[baris,kolom,anchor_i])

                    a = float(self.sigmoid(data[baris, kolom, anchor_i, 4]))
                    box_probs = a
                    if box_probs > self.Treshold_obj:

                        # print("objek :",obj,"iou :",self.sigmoid(data[baris][kolom][anchor_i][0]),"grid_x :",baris,"grid_y :",kolom)
                        # obj+=1
                        # get bounding box dari numpy pada masing* anchor
                        xg = data[baris][kolom][anchor_i][0]
                        yg = data[baris][kolom][anchor_i][1]
                        wg = data[baris][kolom][anchor_i][2]
                        hg = data[baris][kolom][anchor_i][3]

                        temp_dic = {}

                        # konversi ke kordinat anotasi
                        x_predict = self.sigmoid(xg) * 31 + kolom * 32
                        y_predict = self.sigmoid(yg) * 31 + baris * 32
                        w_predict = math.exp(wg) * ANCHOR_BOX[anchor_i][0] * 32
                        h_predict = math.exp(hg) * ANCHOR_BOX[anchor_i][1] * 32

                        # get x,y min max
                        temp_dic['xmin'] = x_predict - (w_predict / 2)
                        temp_dic['ymin'] = y_predict - (h_predict / 2)
                        temp_dic['xmax'] = x_predict + (w_predict / 2)
                        temp_dic['ymax'] = y_predict + (h_predict / 2)
                        temp_dic['obj'] = self.sigmoid(data[baris][kolom][anchor_i][4])

                        if temp_dic['xmin'] > 0 and temp_dic['xmax'] > 0 and temp_dic['ymin'] > 0 and temp_dic[
                            'ymax'] > 0 and temp_dic[
                            'ymax'] < 416 and temp_dic['xmax'] < 416:
                            temp_label_objek.append(temp_dic)
                            # print(temp_dic)
                            temp_label_objek_for_nms[box_probs] = [temp_dic['xmin'], temp_dic['ymin'], temp_dic['xmax'],
                                                                   temp_dic['ymax']]

                            # temp_label_objek_for_nms[a]=[temp_dic['xmin'],temp_dic['ymin'],temp_dic['xmax'],temp_dic['ymax']]
                            # print("objek :",obj,"iou :",self.sigmoid(data[baris][kolom][anchor_i][0]),"/",(data[baris][kolom][anchor_i][0]),"grid_x :",baris,"grid_y :",kolom)
                            # obj += 1
        # print(temp_label_objek_for_nms)
        nms = NMS(temp_label_objek_for_nms, self.max_bbox_limit_fromtop,
                  self.merge_nms)  # 10== max bounding box yang diambil dari urutan terbesar
        bbox_nms = (nms.pred(self.Treshold_nms))
        bbox_nms = (nms.non_max_suppression_fast(self.Treshold_nms))

        # return temp_label_objek
        return bbox_nms

    def draw_citra(self, image, temp_anotasi_mentah):
        # draw bbox dr data target
        # color_i = [(255,0,0), (255,50,0), (255,100,0), (255,150,0), (255,200,0), (255,250,0)]
        for obj in (temp_anotasi_mentah):
            # print(obj)
            xmin = int(int(obj['xmin']) * self.scale_w)
            ymin = int(int(obj['ymin']) * self.scale_h)
            xmax = int(int(obj['xmax']) * self.scale_w)
            ymax = int(int(obj['ymax']) * self.scale_h)

            cv2.rectangle(image, (xmin, ymin), (xmax, ymax), (255, 10, 0), 2)
        return image

class YOLOv2_Video(object):
    def __init__(self, file, tipe_model, max_bbox, treshold_obj=0.5,  treshold_nms=0.5,
                 norm=False, merge=True):
        video_inp = '/content/drive/My Drive/KULIAH/TA/PROGRAM/dataset/Video Test/a/'+str(file)
        video_out = '/content/drive/My Drive/KULIAH/TA/PROGRAM/dataset/Video Test/a/vd_output_3_'+str(file)
        # new_model.summary()
        # new_model.load_weights(tipe_model)
        self.H_citra_reshape = 416
        self.W_citra_reshape = 416
        video_reader = cv2.VideoCapture(video_inp)

        nb_frames = int(video_reader.get(cv2.CAP_PROP_FRAME_COUNT))
        frame_h = int(video_reader.get(cv2.CAP_PROP_FRAME_HEIGHT))
        frame_w = int(video_reader.get(cv2.CAP_PROP_FRAME_WIDTH))
        self.scale_h=frame_h/self.H_citra_reshape
        self.scale_w=frame_w/self.W_citra_reshape

        self.max_bbox_limit_fromtop = max_bbox
        self.n_grid = 13
        self.Treshold_obj = treshold_obj
       
        self.Treshold_nms = treshold_nms
        self.Norm = norm
        self.merge_nms = merge
        self.tipe_model = tipe_model
        self.H_citra_reshape = 416
        self.W_citra_reshape = 416
      
        video_writer = cv2.VideoWriter(video_out,
                               cv2.VideoWriter_fourcc(*'XVID'), 
                               20.0, 
                               (frame_w, frame_h))
        print("total frame",nb_frames)
        for i in tqdm(range(0,nb_frames)):
          ret, image = video_reader.read()
          data = self.get_output(image)
          # print(data)
          boxes = self.konversi_balik(data)
          image=self.draw_video(image,boxes)#image + bbox
          video_writer.write(np.uint8(image))
        
        video_reader.release()
        video_writer.release()
        
    def get_output(self,image):
        image = cv2.resize(image, (self.H_citra_reshape, self.W_citra_reshape))
        image = image / 255
        # membaguskan citra asal
        if self.Norm == True:
            image = image[:, :, ::-1]

        if self.tipe_model==path_model_20:
            model=model_ori(self.tipe_model)
        else:
            model = tf.keras.models.load_model(self.tipe_model, compile=False)

        hasil_matrix = model.predict(image.reshape(1,self.H_citra_reshape, self.W_citra_reshape, 3))
        tf.keras.backend.clear_session()

        if hasil_matrix.shape[4] == 5:
            hasil_matrix = hasil_matrix.reshape(self.n_grid, self.n_grid, len(ANCHOR_BOX), 5)
        else:
            hasil_matrix = hasil_matrix.reshape(self.n_grid, self.n_grid, len(ANCHOR_BOX), 5 + 20)
        return hasil_matrix

    def sigmoid(self, x):
        return 1. / (1. + np.exp(-x))

    def softmax(self, x):
        return np.exp(x) / np.sum(np.exp(x), axis=0)

    def konversi_balik(self, data):

        temp_label_objek = []
        temp_label_objek_for_nms = {}
        obj = 1
        for baris in range(self.n_grid):
            for kolom in range(self.n_grid):
                for anchor_i in range(len(ANCHOR_BOX)):
                    # print(baris,kolom,anchor_i,data[baris,kolom,anchor_i,4],"sig",self.sigmoid(data[baris,kolom,anchor_i,4]),data[baris,kolom,anchor_i])

                    a = float(self.sigmoid(data[baris, kolom, anchor_i, 4]))
                    box_probs = a
                    if box_probs > self.Treshold_obj:

                        # print("objek :",obj,"iou :",self.sigmoid(data[baris][kolom][anchor_i][0]),"grid_x :",baris,"grid_y :",kolom)
                        # obj+=1
                        # get bounding box dari numpy pada masing* anchor
                        xg = data[baris][kolom][anchor_i][0]
                        yg = data[baris][kolom][anchor_i][1]
                        wg = data[baris][kolom][anchor_i][2]
                        hg = data[baris][kolom][anchor_i][3]

                        temp_dic = {}

                        # konversi ke kordinat anotasi
                        x_predict = self.sigmoid(xg) * 31 + kolom * 32
                        y_predict = self.sigmoid(yg) * 31 + baris * 32
                        w_predict = math.exp(wg) * ANCHOR_BOX[anchor_i][0] * 32
                        h_predict = math.exp(hg) * ANCHOR_BOX[anchor_i][1] * 32

                        # get x,y min max
                        temp_dic['xmin'] = x_predict - (w_predict / 2)
                        temp_dic['ymin'] = y_predict - (h_predict / 2)
                        temp_dic['xmax'] = x_predict + (w_predict / 2)
                        temp_dic['ymax'] = y_predict + (h_predict / 2)
                        temp_dic['obj'] = self.sigmoid(data[baris][kolom][anchor_i][4])

                        if temp_dic['xmin'] > 0 and temp_dic['xmax'] > 0 and temp_dic['ymin'] > 0 and temp_dic[
                            'ymax'] > 0 and temp_dic[
                            'ymax'] < 416 and temp_dic['xmax'] < 416:
                            temp_label_objek.append(temp_dic)
                            # print(temp_dic)
                            temp_label_objek_for_nms[box_probs] = [temp_dic['xmin'], temp_dic['ymin'], temp_dic['xmax'],
                                                                   temp_dic['ymax']]

                            # temp_label_objek_for_nms[a]=[temp_dic['xmin'],temp_dic['ymin'],temp_dic['xmax'],temp_dic['ymax']]
                            # print("objek :",obj,"iou :",self.sigmoid(data[baris][kolom][anchor_i][0]),"/",(data[baris][kolom][anchor_i][0]),"grid_x :",baris,"grid_y :",kolom)
                            # obj += 1
        # print(temp_label_objek_for_nms)
        nms = NMS(temp_label_objek_for_nms, self.max_bbox_limit_fromtop,
                  self.merge_nms)  # 10== max bounding box yang diambil dari urutan terbesar
        # bbox_nms = (nms.pred(self.Treshold_nms))
        bbox_nms=(nms.non_max_suppression_fast(self.Treshold_nms))

        # return temp_label_objek
        return bbox_nms

    def draw_video(self,image, temp_anotasi_mentah):
      # draw bbox dr data target
      # color_i = [(255,0,0), (255,50,0), (255,100,0), (255,150,0), (255,200,0), (255,250,0)]
      for obj in (temp_anotasi_mentah):
        # print(obj)
        xmin = int(int(obj['xmin']) * self.scale_w)
        ymin = int(int(obj['ymin']) *self.scale_h)
        xmax = int(int(obj['xmax']) *self.scale_w)
        ymax = int(int(obj['ymax']) *self.scale_h)

        cv2.rectangle(image, (xmin,ymin), (xmax,ymax), (255,10,0), 3)
      return image

class YOLOv2_Webcam(object):
    def __init__(self, tipe_model, max_bbox, treshold_obj=0.5, treshold_nms=0.5,
                 norm=False, merge=True):





        self.max_bbox_limit_fromtop = max_bbox
        self.n_grid = 13
        self.Treshold_obj = treshold_obj

        self.Treshold_nms = treshold_nms
        self.Norm = norm
        self.merge_nms = merge
        self.tipe_model = tipe_model
        self.H_citra_reshape = 416
        self.W_citra_reshape = 416
        # video_reader = cv2.VideoCapture(0)
        frame_h = 480
        frame_w = 640
        self.scale_h=frame_h/self.H_citra_reshape
        self.scale_w=frame_w/self.W_citra_reshape
        

        # while True:

        #     try:
        #         ret, image = video_reader.read()
        #         data = self.get_output(image)
        #         boxes = self.konversi_balik(data)
        #         image = self.draw_video(image, boxes)  # image + bbox
        #         cv2.imshow('frame', image)
        #         cv2.waitKey(1)

        #     except KeyboardInterrupt:
        #         print('exiting...')
        #         break
        VideoCapture()
        eval_js('create()')
        while True:

            try:
                byte = eval_js('capture()')
                image = byte2image(byte)
                data = self.get_output(image)
                boxes = self.konversi_balik(data)
                image = self.draw_video(image, boxes)  # image + bbox
                eval_js('showimg("{}")'.format(image2byte(image)))

            except KeyboardInterrupt:
                print('exiting...')
                break


    def get_output(self, image):
        image = cv2.resize(image, (self.H_citra_reshape, self.W_citra_reshape))
        image = image / 255
        # membaguskan citra asal
        if self.Norm == True:
            image = image[:, :, ::-1]

        if self.tipe_model==path_model_20:
            model=model_ori(self.tipe_model)
        else:
            model = tf.keras.models.load_model(self.tipe_model, compile=False)

        hasil_matrix = model.predict(image.reshape(1, self.H_citra_reshape, self.W_citra_reshape, 3))
        tf.keras.backend.clear_session()

        if hasil_matrix.shape[4] == 5:
            hasil_matrix = hasil_matrix.reshape(self.n_grid, self.n_grid, len(ANCHOR_BOX), 5)
        else:
            hasil_matrix = hasil_matrix.reshape(self.n_grid, self.n_grid, len(ANCHOR_BOX), 5 + 20)
        return hasil_matrix

    def sigmoid(self, x):
        return 1. / (1. + np.exp(-x))

    def softmax(self, x):
        return np.exp(x) / np.sum(np.exp(x), axis=0)

    def konversi_balik(self, data):

        temp_label_objek = []
        temp_label_objek_for_nms = {}
        obj = 1
        for baris in range(self.n_grid):
            for kolom in range(self.n_grid):
                for anchor_i in range(len(ANCHOR_BOX)):
                    # print(baris,kolom,anchor_i,data[baris,kolom,anchor_i,4],"sig",self.sigmoid(data[baris,kolom,anchor_i,4]),data[baris,kolom,anchor_i])

                    a = float(self.sigmoid(data[baris, kolom, anchor_i, 4]))
                    box_probs = a
                    if box_probs > self.Treshold_obj:

                        # print("objek :",obj,"iou :",self.sigmoid(data[baris][kolom][anchor_i][0]),"grid_x :",baris,"grid_y :",kolom)
                        # obj+=1
                        # get bounding box dari numpy pada masing* anchor
                        xg = data[baris][kolom][anchor_i][0]
                        yg = data[baris][kolom][anchor_i][1]
                        wg = data[baris][kolom][anchor_i][2]
                        hg = data[baris][kolom][anchor_i][3]

                        temp_dic = {}

                        # konversi ke kordinat anotasi
                        x_predict = self.sigmoid(xg) * 31 + kolom * 32
                        y_predict = self.sigmoid(yg) * 31 + baris * 32
                        w_predict = math.exp(wg) * ANCHOR_BOX[anchor_i][0] * 32
                        h_predict = math.exp(hg) * ANCHOR_BOX[anchor_i][1] * 32

                        # get x,y min max
                        temp_dic['xmin'] = x_predict - (w_predict / 2)
                        temp_dic['ymin'] = y_predict - (h_predict / 2)
                        temp_dic['xmax'] = x_predict + (w_predict / 2)
                        temp_dic['ymax'] = y_predict + (h_predict / 2)
                        temp_dic['obj'] = self.sigmoid(data[baris][kolom][anchor_i][4])

                        if temp_dic['xmin'] > 0 and temp_dic['xmax'] > 0 and temp_dic['ymin'] > 0 and temp_dic[
                            'ymax'] > 0 and temp_dic[
                            'ymax'] < 416 and temp_dic['xmax'] < 416:
                            temp_label_objek.append(temp_dic)
                            # print(temp_dic)
                            temp_label_objek_for_nms[box_probs] = [temp_dic['xmin'], temp_dic['ymin'], temp_dic['xmax'],
                                                                   temp_dic['ymax']]

                            # temp_label_objek_for_nms[a]=[temp_dic['xmin'],temp_dic['ymin'],temp_dic['xmax'],temp_dic['ymax']]
                            # print("objek :",obj,"iou :",self.sigmoid(data[baris][kolom][anchor_i][0]),"/",(data[baris][kolom][anchor_i][0]),"grid_x :",baris,"grid_y :",kolom)
                            # obj += 1
        # print(temp_label_objek_for_nms)
        nms = NMS(temp_label_objek_for_nms, self.max_bbox_limit_fromtop,
                  self.merge_nms)  # 10== max bounding box yang diambil dari urutan terbesar
        bbox_nms = (nms.pred(self.Treshold_nms))
        bbox_nms = (nms.non_max_suppression_fast(self.Treshold_nms))

        # return temp_label_objek
        return bbox_nms

    def draw_video(self, image, temp_anotasi_mentah):
        # draw bbox dr data target
        # color_i = [(255,0,0), (255,50,0), (255,100,0), (255,150,0), (255,200,0), (255,250,0)]
        for obj in (temp_anotasi_mentah):
            # print(obj)
            xmin = int(int(obj['xmin']) * self.scale_w)
            ymin = int(int(obj['ymin']) *self.scale_h)
            xmax = int(int(obj['xmax']) *self.scale_w)
            ymax = int(int(obj['ymax']) *self.scale_h)

            cv2.rectangle(image, (xmin, ymin), (xmax, ymax), (255, 10, 0), 3)
        return image

def VideoCapture():
  js = Javascript('''
    async function create(){
      div = document.createElement('div');
      document.body.appendChild(div);

      video = document.createElement('video');
      video.setAttribute('playsinline', '');

      div.appendChild(video);

      stream = await navigator.mediaDevices.getUserMedia({video: {facingMode: "environment"}});
      video.srcObject = stream;

      await video.play();

      canvas =  document.createElement('canvas');
      canvas.width = video.videoWidth;
      canvas.height = video.videoHeight;
      canvas.getContext('2d').drawImage(video, 0, 0);

      div_out = document.createElement('div');
      document.body.appendChild(div_out);
      img = document.createElement('img');
      div_out.appendChild(img);
    }

    async function capture(){
        return await new Promise(function(resolve, reject){
            pendingResolve = resolve;
            canvas.getContext('2d').drawImage(video, 0, 0);
            result = canvas.toDataURL('image/jpeg', 0.8);
            pendingResolve(result);
        })
    }

    function showimg(imgb64){
        img.src = "data:image/jpg;base64," + imgb64;
    }

  ''')
  display(js)

def byte2image(byte):
  jpeg = b64decode(byte.split(',')[1])
  im = Image.open(io.BytesIO(jpeg))
  return np.array(im)

def image2byte(image):
  image = Image.fromarray(image)
  buffer = io.BytesIO()
  image.save(buffer, 'jpeg')
  buffer.seek(0)
  x = b64encode(buffer.read()).decode('utf-8')
  return x

def model_ori(path_model_ori):
    # Load network

    model = Sequential()

    # Layer 1
    model.add(Conv2D(16, (3, 3), strides=(1, 1), padding='same', use_bias=False, input_shape=(416, 416, 3)))
    model.add(BatchNormalization())
    model.add(LeakyReLU(alpha=0.1))
    model.add(MaxPooling2D(pool_size=(2, 2)))

    # Layer 2 - 5
    for i in range(0, 4):
        model.add(Conv2D(32 * (2 ** i), (3, 3), strides=(1, 1), padding='same', use_bias=False))
        model.add(BatchNormalization())
        model.add(LeakyReLU(alpha=0.1))
        model.add(MaxPooling2D(pool_size=(2, 2)))

    # Layer 6
    model.add(Conv2D(512, (3, 3), strides=(1, 1), padding='same', use_bias=False))
    model.add(BatchNormalization())
    model.add(LeakyReLU(alpha=0.1))
    model.add(MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding='same'))

    # Layer 7 - 8
    for _ in range(0, 2):
        model.add(Conv2D(1024, (3, 3), strides=(1, 1), padding='same', use_bias=False))
        model.add(BatchNormalization())
        model.add(LeakyReLU(alpha=0.1))

    # Layer 9
    model.add(Conv2D(len(ANCHOR_BOX) * (4 + 1 + 20), (1, 1), strides=(1, 1), kernel_initializer='he_normal'))
    model.add(Activation('linear'))
    model.add(Reshape((13, 13, len(ANCHOR_BOX), 4 + 1 + 20)))

    model.load_weights(path_model_ori)
    # model.summary()
    return model

##TESTING


path_model_16a = "/content/drive/My Drive/KULIAH/TA/PROGRAM/dataset/MODEL FIX/(2)2_6_CUSTOM_YOLO_bn=64_epoch=200_linear(pretrained).h5"
path_model_17a = "/content/drive/My Drive/KULIAH/TA/PROGRAM/dataset/MODEL FIX/(2a)3_6_CUSTOM_YOLO_bn=64_epoch=100_linear(pretrained).h5"
path_model_17b = "/content/drive/My Drive/KULIAH/TA/PROGRAM/dataset/MODEL FIX/(2b)3_6_CUSTOM_YOLO_bn=64_epoch=1000_linear.h5"

path_model_20 = "/content/drive/My Drive/KULIAH/TA/PROGRAM/dataset/tiny-yolo-voc.h5"
list_path_model=[path_model_16a,path_model_17a,path_model_17b,path_model_20]

data_test=parse_anotasi(folder_citra_test_anno)
a=YOLOv2(data_test[20],path_model_16a,max_bbox=10,treshold_obj=0.53,treshold_eval=0.2,treshold_nms=0.5,norm=True)#merge berulang loop on set NMS
# plt.savefig('HASIL OUTPUT/MODEL 16a (2)2_6_CUSTOM_YOLO_bn=64_epoch=50_linear(pretrained).h5/foo.png')
plt.show()
tf.keras.backend.clear_session()


#CITRA
a=YOLOv2_Citra('wwwanccmnusimagesnews90BikeWinner2.png',path_model_16a,max_bbox=10,treshold_obj=0.53,treshold_nms=0.5,norm=True)
# for i in list_path_model:
#   YOLOv2_Citra('nonantumcomgallerygalleriesChicacoJul2002imagesTee20the20Pedestrian.png',i,max_bbox=10,treshold_obj=0.53,treshold_nms=0.5,norm=True,merge=True)
#   print(i,"*"*100)

#VIDEO
# a=YOLOv2_Video('videoplayback (2).mp4',path_model_17b,max_bbox=10,treshold_obj=0.8,treshold_nms=0.8,norm=True)#merge berulang loop on set NMS

#WEBCAM
# a=YOLOv2_Webcam(path_model_16a,max_bbox=10,treshold_obj=0.95,treshold_nms=0.9,norm=True)#merge berulang loop on set NMS
#https://www.youtube.com/watch?v=1VziTgVt4GQ

